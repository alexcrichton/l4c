.file	"../tests2/triceratops-ret05.l4"
.globl _c0_main
_c0_a:
	addq $-24, %rsp
	movq %rbx, 16(%rsp)
	movq %rdi, %r9
.a_0:
	movl $0, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_b
	movq %rbx, %r9
	movl $0, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %edx
	movl $0, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %ecx
	movl $0, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	addq %r8, %r9
	movl (%r9), %r8d
	movl %edx, %r9d
	imull %ecx, %r9d
	movl %r9d, %eax
	addl %r8d, %eax
	movq 16(%rsp), %rbx
	addq $24, %rsp
	ret
_c0_b:
	addq $-24, %rsp
	movq %rbx, 16(%rsp)
	movq %rdi, %r9
.b_0:
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r9, %rdx
	addq %r8, %rdx
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r9, %rdx
	addq %r8, %rdx
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r9, %rdx
	addq %r8, %rdx
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_c
	movq %rbx, %r9
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %edx
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %ecx
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	addq %r8, %r9
	movl (%r9), %r8d
	movl %edx, %r9d
	imull %ecx, %r9d
	movl %r9d, %eax
	addl %r8d, %eax
	movq 16(%rsp), %rbx
	addq $24, %rsp
	ret
_c0_c:
	addq $-24, %rsp
	movq %rbx, 16(%rsp)
	movq %rdi, %r9
.c_0:
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r9, %rdx
	addq %r8, %rdx
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r9, %rdx
	addq %r8, %rdx
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_d
	movq %rbx, %r9
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %edx
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %r9, %r8
	addq %rcx, %r8
	movl (%r8), %ecx
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	addq %r8, %r9
	movl (%r9), %r8d
	movl %edx, %r9d
	imull %ecx, %r9d
	movl %r9d, %eax
	addl %r8d, %eax
	movq 16(%rsp), %rbx
	addq $24, %rsp
	ret
_c0_d:
	addq $-8, %rsp
.d_0:
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %rdx
	addq %r8, %rdx
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, (%rdx)
	addl $1, (%rdx)
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %edx
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %ecx
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl (%r9), %r8d
	movl %edx, %r9d
	imull %ecx, %r9d
	movl %r9d, %eax
	addl %r8d, %eax
	addq $8, %rsp
	ret
_c0_main:
	addq $-40, %rsp
	movq %r13, 16(%rsp)
	movq %r12, 24(%rsp)
	movq %rbx, 32(%rsp)
.main_0:
	movq $4, %rdi
	movq $4, %rsi
	callq calloc
	movq %rax, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_a
	movq %rbx, %r9
	movl %eax, %r8d
	movq %r9, %rdi
	movq %r8, %r12
	movq %r9, %rbx
	callq _c0_b
	movq %r12, %r8
	movq %rbx, %r9
	movl %eax, %edx
	movq %r9, %rdi
	movq %rdx, %r13
	movq %r8, %r12
	movq %r9, %rbx
	callq _c0_c
	movq %r13, %rdx
	movq %r12, %r8
	movq %rbx, %r9
	movl %eax, %ecx
	movq %r9, %rdi
	movq %rdx, %r13
	movq %rcx, %r12
	movq %r8, %rbx
	callq _c0_d
	movq %r13, %rdx
	movq %r12, %rcx
	movq %rbx, %r8
	movl %r8d, %r9d
	addl %edx, %r9d
	addl %ecx, %r9d
	addl %eax, %r9d
	movl %r9d, %eax
	movq 16(%rsp), %r13
	movq 24(%rsp), %r12
	movq 32(%rsp), %rbx
	addq $40, %rsp
	ret
.ident	"15-411 L4 reference compiler"
