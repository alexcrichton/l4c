.file	"../tests2/saltopus-brainfuck.l4"
.globl _c0_main
_c0_cksum_start:
	addq $-8, %rsp
.cksum_start_0:
	movq $1, %rdi
	movq $8, %rsi
	callq calloc
	addq $8, %rsp
	ret
_c0_cksum_update:
	addq $-8, %rsp
.cksum_update_0:
	movq $0, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %r8d, %eax
	addl %esi, %eax
	movl $65521, %r8d
	cltd
	idivl %r8d
	movq $0, %r8
	movq %rdi, %rcx
	addq %r8, %rcx
	movl %edx, (%rcx)
	movq $4, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %edx
	movq $0, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl %edx, %eax
	addl %r8d, %eax
	movl $65521, %r8d
	cltd
	idivl %r8d
	movl %edx, %ecx
	movq $4, %r8
	movq %rdi, %rdx
	addq %r8, %rdx
	movl %ecx, (%rdx)
	movq %rdi, %rax
	addq $8, %rsp
	ret
_c0_cksum_finish:
	addq $-8, %rsp
.cksum_finish_0:
	movq $4, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl (%r8), %ecx
	movq $0, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl (%r9), %r8d
	movl %ecx, %r9d
	sall $16, %r9d
	movl %r9d, %eax
	orl %r8d, %eax
	addq $8, %rsp
	ret
_c0_parse:
	addq $-40, %rsp
	movq %r13, 16(%rsp)
	movq %r12, 24(%rsp)
	movq %rbx, 32(%rsp)
	movq %rdi, %r9
	movq %rsi, %r8
	movq %rdx, %r13
.parse_0:
	movl $0, %edx
	movl $0, %ecx
.parse_19:
	movl %ecx, %r12d
	movl %edx, %eax
.parse_1:
	movl $1, %esi
	movl $16384, %edx
	movl %r12d, %ecx
	cmpl %edx, %ecx
	setl %cl
	movzbl %cl, %ecx
	cmpl %ecx, %esi
	jnz .parse_25
.parse_2:
	movl %r12d, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r9, %rcx
	addq %rdx, %rcx
	movl (%rcx), %edi
	movl $1, %esi
	movl $7, %edx
	movl %edi, %ecx
	cmpl %edx, %ecx
	sete %cl
	movzbl %cl, %ecx
	cmpl %ecx, %esi
	jnz .parse_5
.parse_3:
	jmp .parse_24
.parse_5:
.parse_6:
	movl %r12d, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r9, %rcx
	addq %rdx, %rcx
	movl (%rcx), %ecx
	movl $1, %esi
	movl $5, %edx
	cmpl %edx, %ecx
	sete %cl
	movzbl %cl, %ecx
	cmpl %ecx, %esi
	jnz .parse_8
.parse_7:
	movl %eax, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r8, %rcx
	addq %rdx, %rcx
	movl %r12d, (%rcx)
	movl %eax, %ecx
	addl $1, %ecx
.parse_21:
	movl %ecx, %ebx
.parse_9:
	movl %r12d, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r9, %rcx
	addq %rdx, %rcx
	movl (%rcx), %ecx
	movl $1, %esi
	movl $6, %edx
	cmpl %edx, %ecx
	sete %cl
	movzbl %cl, %ecx
	cmpl %ecx, %esi
	jnz .parse_15
.parse_10:
	movl $1, %esi
	movl $0, %edx
	movl %ebx, %ecx
	cmpl %edx, %ecx
	sete %cl
	movzbl %cl, %ecx
	cmpl %ecx, %esi
	jnz .parse_13
.parse_11:
	movl $0, %eax
	movq 16(%rsp), %r13
	movq 24(%rsp), %r12
	movq 32(%rsp), %rbx
	addq $40, %rsp
	ret
.parse_13:
.parse_14:
	movl %ebx, %eax
	subl $1, %eax
	movl %eax, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r8, %rcx
	addq %rdx, %rcx
	movl (%rcx), %edi
	movl %r12d, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r13, %rcx
	addq %rdx, %rcx
	movl %edi, (%rcx)
	movl %eax, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r8, %rcx
	addq %rdx, %rcx
	movl (%rcx), %esi
	movl %esi, %ecx
	imull $4, %ecx
	movslq %ecx, %rdx
	movq %r13, %rcx
	addq %rdx, %rcx
	movl %r12d, (%rcx)
.parse_23:
	movl %eax, %edx
.parse_16:
	movl %r12d, %ecx
	addl $1, %ecx
.parse_18:
	movl %ecx, %r12d
	movl %edx, %eax
	jmp .parse_1
.parse_15:
.parse_22:
	movl %ebx, %edx
	jmp .parse_16
.parse_8:
.parse_20:
	movl %eax, %ebx
	jmp .parse_9
.parse_25:
.parse_17:
	movl $0, %r9d
	cmpl %r9d, %eax
	sete %al
	movzbl %al, %eax
	movq 16(%rsp), %r13
	movq 24(%rsp), %r12
	movq 32(%rsp), %rbx
	addq $40, %rsp
	ret
.parse_24:
	jmp .parse_17
_c0_main:
	addq $-232, %rsp
	movq %rbp, 12(%rsp)
	movq %r15, 20(%rsp)
	movq %r14, 28(%rsp)
	movq %r13, 36(%rsp)
	movq %r12, 44(%rsp)
	movq %rbx, 52(%rsp)
.main_0:
	movq %rcx, 60(%rsp)
	movq %r8, 68(%rsp)
	movq %r9, %r14
	callq _c0_cksum_start
	movq 60(%rsp), %rcx
	movq 68(%rsp), %r8
	movq %r14, %r9
	movq %rax, 76(%rsp)
	movl $2, %edx
	imull $16384, %edx
	movslq %edx, %rdi
	movq $4, %rsi
	movq %rcx, 60(%rsp)
	movq %r8, 68(%rsp)
	movq %r9, %r14
	callq calloc
	movq 60(%rsp), %rcx
	movq 68(%rsp), %r8
	movq %r14, %r9
	movq %rax, %r14
	movq $16384, %rdi
	movq $4, %rsi
	movq %rcx, 84(%rsp)
	movq %r8, 60(%rsp)
	movq %r9, 68(%rsp)
	callq calloc
	movq 84(%rsp), %rcx
	movq 60(%rsp), %r8
	movq 68(%rsp), %r9
	movq %rax, 68(%rsp)
	movq $16384, %rdi
	movq $4, %rsi
	movq %rcx, 92(%rsp)
	movq %r8, 84(%rsp)
	movq %r9, 60(%rsp)
	callq calloc
	movq 92(%rsp), %rcx
	movq 84(%rsp), %r8
	movq 60(%rsp), %r9
	movq %rax, %rdx
	movq $16384, %rdi
	movq $4, %rsi
	movq %rdx, 100(%rsp)
	movq %rcx, 92(%rsp)
	movq %r8, 84(%rsp)
	movq %r9, 60(%rsp)
	callq calloc
	movq 100(%rsp), %rdx
	movq 92(%rsp), %rcx
	movq 84(%rsp), %r8
	movq 60(%rsp), %r9
	movq %rax, 84(%rsp)
	movl $0, 132(%rsp)
	movq 68(%rsp), %rdi
	movq %rdx, 108(%rsp)
	movq %rcx, 116(%rsp)
	movq %r8, 100(%rsp)
	movq %r9, 92(%rsp)
	callq _c0_initialize_program
	movq 108(%rsp), %rdx
	movq 116(%rsp), %rcx
	movq 100(%rsp), %r8
	movq 92(%rsp), %r9
	movq 68(%rsp), %rdi
	movq %rdx, %rsi
	movq 84(%rsp), %rdx
	movq %rcx, 116(%rsp)
	movq %r8, 100(%rsp)
	movq %r9, 92(%rsp)
	callq _c0_parse
	movq 116(%rsp), %rcx
	movq 100(%rsp), %r8
	movq 92(%rsp), %r9
	movl $1, %esi
	movl $1, %edx
	xorl %eax, %edx
	cmpl %edx, %esi
	jnz .main_3
.main_1:
	movl $0, %eax
	subl $1, %eax
	movq 12(%rsp), %rbp
	movq 20(%rsp), %r15
	movq 28(%rsp), %r14
	movq 36(%rsp), %r13
	movq 44(%rsp), %r12
	movq 52(%rsp), %rbx
	addq $232, %rsp
	ret
.main_3:
.main_4:
	movl $0, %edx
.main_54:
	movl 132(%rsp), %r10d
	movl %r10d, 136(%rsp)
	movl %edx, 140(%rsp)
.main_5:
	movl $1, %edi
	movl $16384, %edx
	movl 140(%rsp), %esi
	cmpl %edx, %esi
	setl %sil
	movzbl %sil, %esi
	cmpl %esi, %edi
	jnz .main_60
.main_6:
	movl 140(%rsp), %edx
	imull $4, %edx
	movslq %edx, %rsi
	movq 68(%rsp), %rdx
	addq %rsi, %rdx
	movl (%rdx), %edx
	movl $1, %eax
	movl $0, %edi
	movl %edx, %esi
	cmpl %edi, %esi
	sete %sil
	movzbl %sil, %esi
	cmpl %esi, %eax
	jnz .main_9
.main_7:
	movl 136(%rsp), %esi
	imull $4, %esi
	movslq %esi, %rsi
	movq %r14, %rax
	addq %rsi, %rax
	movl 136(%rsp), %esi
	imull $4, %esi
	movslq %esi, %rdi
	movq %r14, %rsi
	addq %rdi, %rsi
	movl (%rsi), %esi
	movl %esi, (%rax)
	addl $1, (%rax)
	movl 140(%rsp), %r10d
	movl %r10d, 144(%rsp)
	addl $1, 144(%rsp)
	jmp .main_53
.main_9:
.main_10:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %rsi
	movq 68(%rsp), %r9
	addq %rsi, %r9
	movl (%r9), %r10d
	movl %r10d, 132(%rsp)
	movl $1, %esi
	movl $1, %edi
	movl 132(%rsp), %r9d
	cmpl %edi, %r9d
	sete %r9b
	movzbl %r9b, %r9d
	cmpl %r9d, %esi
	jnz .main_13
.main_11:
	movl 136(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r9
	movq %r14, %rdi
	addq %r9, %rdi
	movl 136(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %rsi
	movq %r14, %r9
	addq %rsi, %r9
	movl (%r9), %r9d
	movl %r9d, (%rdi)
	subl $1, (%rdi)
	movl 140(%rsp), %r10d
	movl %r10d, 148(%rsp)
	addl $1, 148(%rsp)
	jmp .main_52
.main_13:
.main_14:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq 68(%rsp), %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 152(%rsp)
	movl $1, %esi
	movl $2, %r8d
	movl 152(%rsp), %r9d
	cmpl %r8d, %r9d
	sete %r9b
	movzbl %r9b, %r9d
	cmpl %r9d, %esi
	jnz .main_17
.main_15:
	movl 136(%rsp), %r10d
	movl %r10d, 156(%rsp)
	addl $1, 156(%rsp)
	movl 140(%rsp), %r10d
	movl %r10d, 160(%rsp)
	addl $1, 160(%rsp)
	jmp .main_51
.main_17:
.main_18:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq 68(%rsp), %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 164(%rsp)
	movl $1, %esi
	movl $3, %r8d
	movl 164(%rsp), %r9d
	cmpl %r8d, %r9d
	sete %r9b
	movzbl %r9b, %r9d
	cmpl %r9d, %esi
	jnz .main_21
.main_19:
	movl 136(%rsp), %r10d
	movl %r10d, 168(%rsp)
	subl $1, 168(%rsp)
	movl 140(%rsp), %r10d
	movl %r10d, 172(%rsp)
	addl $1, 172(%rsp)
	jmp .main_50
.main_21:
.main_22:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq 68(%rsp), %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 176(%rsp)
	movl $1, %ecx
	movl $4, %r8d
	movl 176(%rsp), %r9d
	cmpl %r8d, %r9d
	sete %r9b
	movzbl %r9b, %r9d
	cmpl %r9d, %ecx
	jnz .main_25
.main_23:
	movl 136(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq %r14, %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 180(%rsp)
	movl 180(%rsp), %edi
	movq %rdx, %r12
	callq printchar
	movq %r12, %rdx
	movl %eax, 184(%rsp)
	movl 184(%rsp), %r10d
	movslq %r10d, %r10
	movq %r10, 124(%rsp)
	movl 136(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq %r14, %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 188(%rsp)
	movq 76(%rsp), %rdi
	movl 188(%rsp), %esi
	movq %rdx, %r12
	callq _c0_cksum_update
	movq %r12, %rdx
	movq %rax, %rbp
	movq %rbp, %r13
	movl 140(%rsp), %r12d
	addl $1, %r12d
	jmp .main_49
.main_25:
.main_26:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r9
	movq 68(%rsp), %r8
	addq %r9, %r8
	movl (%r8), %esi
	movl $1, %ecx
	movl $5, %r9d
	movl %esi, %r8d
	cmpl %r9d, %r8d
	sete %r8b
	movzbl %r8b, %r8d
	cmpl %r8d, %ecx
	jnz .main_32
.main_27:
	movl 136(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq %r14, %r9
	addq %r8, %r9
	movl (%r9), %r10d
	movl %r10d, 192(%rsp)
	movl $1, %r9d
	movl $0, %r8d
	movl 192(%rsp), %ecx
	cmpl %r8d, %ecx
	sete %cl
	movzbl %cl, %ecx
	cmpl %ecx, %r9d
	jnz .main_29
.main_28:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r9
	movq 84(%rsp), %r8
	addq %r9, %r8
	movl (%r8), %r8d
	movl %r8d, %r9d
.main_56:
	movl %r8d, 196(%rsp)
.main_30:
	movl %r9d, 200(%rsp)
	addl $1, 200(%rsp)
	jmp .main_48
.main_29:
.main_55:
	movl 204(%rsp), %r10d
	movl %r10d, 196(%rsp)
	movl 140(%rsp), %r9d
	jmp .main_30
.main_32:
.main_33:
	movl 140(%rsp), %r9d
	imull $4, %r9d
	movslq %r9d, %r8
	movq 68(%rsp), %r9
	addq %r8, %r9
	movl (%r9), %r9d
	movl $1, %edi
	movl $6, %ecx
	movl %r9d, %r8d
	cmpl %ecx, %r8d
	sete %r8b
	movzbl %r8b, %r8d
	cmpl %r8d, %edi
	jnz .main_39
.main_34:
	movl 136(%rsp), %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %r14, %rcx
	addq %r8, %rcx
	movl (%rcx), %r10d
	movl %r10d, 208(%rsp)
	movl $1, %edi
	movl $0, %ecx
	movl 208(%rsp), %r8d
	cmpl %ecx, %r8d
	setne %r8b
	movzbl %r8b, %r8d
	cmpl %r8d, %edi
	jnz .main_36
.main_35:
	movl 140(%rsp), %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq 84(%rsp), %rcx
	addq %r8, %rcx
	movl (%rcx), %r8d
	movl %r8d, %ecx
.main_58:
	movl %r8d, 212(%rsp)
	movl %ecx, %r8d
.main_37:
	movl %r8d, %r15d
	addl $1, %r15d
	jmp .main_47
.main_36:
.main_57:
	movl %ebx, 212(%rsp)
	movl 140(%rsp), %r8d
	jmp .main_37
.main_39:
.main_40:
	movl 140(%rsp), %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq 68(%rsp), %r8
	addq %rcx, %r8
	movl (%r8), %r8d
	movl $1, %ecx
	movl $7, %eax
	movl %r8d, %edi
	cmpl %eax, %edi
	sete %dil
	movzbl %dil, %edi
	cmpl %edi, %ecx
	jnz .main_43
.main_41:
	jmp .main_59
.main_43:
.main_44:
	movl $42, %eax
	movl $0, %ecx
	cltd
	idivl %ecx
	movslq %eax, %rcx
	movl 140(%rsp), %edi
	addl $1, %edi
.main_46:
	movl %r8d, 216(%rsp)
	movl %r9d, 220(%rsp)
	movl %esi, 224(%rsp)
	movl 176(%rsp), %ecx
	movl 164(%rsp), %r10d
	movl %r10d, 228(%rsp)
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl %edi, 140(%rsp)
	jmp .main_5
.main_60:
.main_45:
	movq 76(%rsp), %rdi
	callq _c0_cksum_finish
	movq 12(%rsp), %rbp
	movq 20(%rsp), %r15
	movq 28(%rsp), %r14
	movq 36(%rsp), %r13
	movq 44(%rsp), %r12
	movq 52(%rsp), %rbx
	addq $232, %rsp
	ret
.main_59:
	jmp .main_45
.main_47:
	movl 212(%rsp), %ebx
	movl %r9d, 220(%rsp)
	movl %esi, 224(%rsp)
	movl 176(%rsp), %ecx
	movl 164(%rsp), %r10d
	movl %r10d, 228(%rsp)
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl %r15d, 140(%rsp)
	jmp .main_5
.main_48:
	movl 196(%rsp), %r10d
	movl %r10d, 204(%rsp)
	movl %esi, 224(%rsp)
	movl 176(%rsp), %ecx
	movl 164(%rsp), %r10d
	movl %r10d, 228(%rsp)
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl 200(%rsp), %r10d
	movl %r10d, 140(%rsp)
	jmp .main_5
.main_49:
	movl 176(%rsp), %ecx
	movl 164(%rsp), %r10d
	movl %r10d, 228(%rsp)
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl %r12d, 140(%rsp)
	jmp .main_5
.main_50:
	movl 164(%rsp), %r10d
	movl %r10d, 228(%rsp)
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl 168(%rsp), %r10d
	movl %r10d, 136(%rsp)
	movl 172(%rsp), %r10d
	movl %r10d, 140(%rsp)
	jmp .main_5
.main_51:
	movl 152(%rsp), %r8d
	movl 132(%rsp), %r9d
	movl 156(%rsp), %r10d
	movl %r10d, 136(%rsp)
	movl 160(%rsp), %r10d
	movl %r10d, 140(%rsp)
	jmp .main_5
.main_52:
	movl 132(%rsp), %r9d
	movl 148(%rsp), %r10d
	movl %r10d, 140(%rsp)
	jmp .main_5
.main_53:
	movl 144(%rsp), %r10d
	movl %r10d, 140(%rsp)
	jmp .main_5
_c0_initialize_program_0:
	addq $-8, %rsp
.initialize_program_0_0:
	movl $0, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $1, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $2, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $3, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $4, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $5, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $6, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $7, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $8, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $9, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $10, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $11, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $12, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $13, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $14, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $15, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $16, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $17, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $18, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $19, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_1:
	addq $-8, %rsp
.initialize_program_1_0:
	movl $20, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $21, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $22, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $23, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $24, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $25, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $26, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $27, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $28, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $29, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $30, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $31, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $32, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $33, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $34, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $35, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $36, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $37, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $38, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $39, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $3, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_2:
	addq $-8, %rsp
.initialize_program_2_0:
	movl $40, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $41, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $42, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $43, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $44, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $45, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $46, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $47, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $48, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $49, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $50, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $51, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $52, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $53, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $54, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $55, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $56, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $57, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $58, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $59, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_3:
	addq $-8, %rsp
.initialize_program_3_0:
	movl $60, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $61, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $62, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $63, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $64, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $65, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $66, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $67, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $68, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $69, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $70, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $71, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $72, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $73, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $74, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $75, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $76, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $77, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $78, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $79, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $6, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_4:
	addq $-8, %rsp
.initialize_program_4_0:
	movl $80, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $81, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $82, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $83, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $84, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $85, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $86, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $87, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $88, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $89, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $90, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $91, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $92, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $93, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $94, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $95, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $96, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $97, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $98, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $99, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_5:
	addq $-8, %rsp
.initialize_program_5_0:
	movl $100, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $101, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $102, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $103, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $104, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $105, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $106, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $107, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $108, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $109, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $110, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $111, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $112, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $113, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $114, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $115, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $116, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $117, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $118, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $119, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_6:
	addq $-8, %rsp
.initialize_program_6_0:
	movl $120, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $121, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $122, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $123, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $124, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $125, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $126, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $127, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $128, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $129, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $130, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $131, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $132, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $133, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $134, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $135, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $136, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $137, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $138, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $139, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_7:
	addq $-8, %rsp
.initialize_program_7_0:
	movl $140, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $141, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $142, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $143, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $144, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $145, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $146, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $147, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $148, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $149, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $150, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $151, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $152, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $153, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $154, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $155, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $156, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $157, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $158, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $159, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_8:
	addq $-8, %rsp
.initialize_program_8_0:
	movl $160, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $161, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $162, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $163, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $164, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $165, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $166, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $167, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $168, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $169, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $170, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $171, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $172, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $173, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $174, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $175, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $176, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $177, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $178, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $179, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_9:
	addq $-8, %rsp
.initialize_program_9_0:
	movl $180, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $181, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $182, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $183, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $184, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $185, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $186, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $187, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $188, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $189, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $190, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $191, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $192, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $193, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $194, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $195, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $196, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $197, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $198, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $199, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $5, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_10:
	addq $-8, %rsp
.initialize_program_10_0:
	movl $200, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $201, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $202, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $203, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $204, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $205, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $206, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $207, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $208, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $209, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $210, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $211, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $212, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $213, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $214, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $215, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $216, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $217, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $218, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $219, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_11:
	addq $-8, %rsp
.initialize_program_11_0:
	movl $220, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $221, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $222, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $223, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $224, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $225, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $226, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $227, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $228, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $229, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $230, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $231, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $232, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $233, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $234, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $235, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $236, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $237, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $238, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $239, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_12:
	addq $-8, %rsp
.initialize_program_12_0:
	movl $240, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $241, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $242, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $243, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $244, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $245, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $246, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $247, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $248, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $249, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $250, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $251, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $252, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $253, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $254, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $255, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $256, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $257, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $258, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $259, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_13:
	addq $-8, %rsp
.initialize_program_13_0:
	movl $260, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $261, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $262, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $263, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $264, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $265, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $266, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $267, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $268, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $269, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $270, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $271, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $272, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $273, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $274, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $275, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $276, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $277, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $278, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $279, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_14:
	addq $-8, %rsp
.initialize_program_14_0:
	movl $280, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $281, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $282, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $283, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $284, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $285, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $286, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $287, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $288, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $289, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $290, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $291, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $292, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $293, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $294, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $295, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $296, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $297, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $298, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $299, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_15:
	addq $-8, %rsp
.initialize_program_15_0:
	movl $300, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $301, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $302, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $303, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $304, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $305, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $306, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $307, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $308, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $309, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $310, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $311, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $312, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $313, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $314, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $315, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $316, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $317, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $318, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $319, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_16:
	addq $-8, %rsp
.initialize_program_16_0:
	movl $320, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $321, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $322, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $323, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $324, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $325, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $326, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $327, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $328, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $329, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $330, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $331, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $332, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $333, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $334, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $335, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $336, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $337, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $338, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $339, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_17:
	addq $-8, %rsp
.initialize_program_17_0:
	movl $340, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $341, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $342, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $343, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $344, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $345, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $346, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $347, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $348, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $349, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $350, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $351, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $352, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $353, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $354, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $355, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $356, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $357, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $358, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $359, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_18:
	addq $-8, %rsp
.initialize_program_18_0:
	movl $360, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $361, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $362, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $363, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $364, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $365, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $366, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $367, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $368, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $369, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $370, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $371, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $372, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $373, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $374, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $375, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $376, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $377, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $378, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $379, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_19:
	addq $-8, %rsp
.initialize_program_19_0:
	movl $380, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $381, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $382, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $383, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $384, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $385, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $386, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $387, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $388, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $389, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $390, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $391, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $392, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $393, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $394, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $395, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $396, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $397, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $398, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $399, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $6, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_20:
	addq $-8, %rsp
.initialize_program_20_0:
	movl $400, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $401, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $402, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $403, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $404, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $405, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $406, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $407, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $408, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $409, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $410, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $411, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $412, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $413, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $414, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $415, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $416, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $417, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $418, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $419, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_21:
	addq $-8, %rsp
.initialize_program_21_0:
	movl $420, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $421, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $422, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $423, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $424, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $425, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $426, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $427, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $428, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $429, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $430, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $431, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $432, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $433, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $434, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $435, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $436, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $437, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $438, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $439, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_22:
	addq $-8, %rsp
.initialize_program_22_0:
	movl $440, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $441, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $442, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $443, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $444, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $445, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $446, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $447, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $448, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $449, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $450, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $451, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $452, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $453, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $454, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $455, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $456, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $457, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $458, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $459, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_23:
	addq $-8, %rsp
.initialize_program_23_0:
	movl $460, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $461, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $462, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $463, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $464, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $465, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $466, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $467, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $468, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $469, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $470, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $471, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $472, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $473, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $474, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $475, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $476, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $477, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $478, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $479, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_24:
	addq $-8, %rsp
.initialize_program_24_0:
	movl $480, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $481, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $482, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $483, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $484, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $485, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $486, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $487, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $488, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $489, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $490, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $491, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $492, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $493, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $494, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $495, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $496, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $497, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $498, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $499, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_25:
	addq $-8, %rsp
.initialize_program_25_0:
	movl $500, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $501, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $502, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $503, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $504, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $505, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $506, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $507, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $508, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $509, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $510, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $511, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $512, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $513, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $514, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $515, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $516, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $517, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $518, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $519, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_26:
	addq $-8, %rsp
.initialize_program_26_0:
	movl $520, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $521, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $522, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $523, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $524, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $525, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $526, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $527, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $528, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $529, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $530, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $531, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $532, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $533, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $534, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $535, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $536, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $537, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $538, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $539, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_27:
	addq $-8, %rsp
.initialize_program_27_0:
	movl $540, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $541, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $542, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $543, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $544, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $545, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $546, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $547, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $548, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $549, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $550, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $551, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $552, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $553, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $554, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $555, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $556, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $557, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $558, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $559, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_28:
	addq $-8, %rsp
.initialize_program_28_0:
	movl $560, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $561, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $562, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $563, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $564, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $565, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $566, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $567, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $568, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $569, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $570, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $571, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $572, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $573, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $574, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $575, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $576, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $577, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $578, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $579, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_29:
	addq $-8, %rsp
.initialize_program_29_0:
	movl $580, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $581, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $582, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $583, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $584, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $585, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $586, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $587, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $588, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $589, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $590, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $591, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $592, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $593, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $594, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $595, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $596, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $597, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $598, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $599, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $3, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_30:
	addq $-8, %rsp
.initialize_program_30_0:
	movl $600, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $601, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $602, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $603, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $604, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $605, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $606, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $607, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $608, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $609, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $610, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $611, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $612, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $613, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $614, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $615, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $616, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $617, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $618, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $619, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_31:
	addq $-8, %rsp
.initialize_program_31_0:
	movl $620, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $621, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $622, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $623, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $624, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $625, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $626, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $627, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $628, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $629, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $630, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $631, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $632, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $633, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $634, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $635, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $636, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $637, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $638, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $639, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $3, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_32:
	addq $-8, %rsp
.initialize_program_32_0:
	movl $640, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $641, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $642, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $643, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $644, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $645, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $646, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $647, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $648, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $649, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $650, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $651, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $652, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $653, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $654, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $655, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $656, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $657, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $658, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $659, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $5, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_33:
	addq $-8, %rsp
.initialize_program_33_0:
	movl $660, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $661, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $662, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $663, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $664, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $665, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $666, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $667, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $668, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $669, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $670, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $671, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $672, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $673, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $674, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $675, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $676, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $677, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $678, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $679, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $5, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_34:
	addq $-8, %rsp
.initialize_program_34_0:
	movl $680, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $681, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $682, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $683, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $684, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $685, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $686, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $687, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $688, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $689, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $690, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $691, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $692, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $693, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $694, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $695, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $696, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $697, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $698, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $699, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $2, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_35:
	addq $-8, %rsp
.initialize_program_35_0:
	movl $700, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $701, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $702, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $703, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $704, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $705, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $706, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $707, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $708, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $709, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $710, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $711, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $712, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $713, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $714, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $715, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $716, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $717, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $718, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $719, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $6, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_36:
	addq $-8, %rsp
.initialize_program_36_0:
	movl $720, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $721, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $722, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $723, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $724, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $725, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $726, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $727, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $728, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $729, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $730, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $731, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $732, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $733, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $734, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $735, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $736, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $737, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $738, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $739, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $5, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_37:
	addq $-8, %rsp
.initialize_program_37_0:
	movl $740, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $741, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $742, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $743, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $744, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $745, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $746, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $747, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $748, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $749, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $750, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $751, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $752, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $753, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $754, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $755, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $756, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $757, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $758, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $759, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $0, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_38:
	addq $-8, %rsp
.initialize_program_38_0:
	movl $760, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $761, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $762, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $763, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $764, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $765, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $766, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $767, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $768, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $769, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $770, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $771, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $772, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $773, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $774, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $775, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $776, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $777, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $778, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $779, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $3, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_39:
	addq $-8, %rsp
.initialize_program_39_0:
	movl $780, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $781, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $782, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $783, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $784, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $785, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $786, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $787, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $788, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $789, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $790, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $791, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $792, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $793, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $794, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $795, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $796, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $797, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $798, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $799, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $6, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_40:
	addq $-8, %rsp
.initialize_program_40_0:
	movl $800, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $801, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $802, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $803, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $804, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $805, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $806, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $807, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $808, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $809, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $810, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $811, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $812, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $813, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $814, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $815, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $816, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $817, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $818, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $819, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_41:
	addq $-8, %rsp
.initialize_program_41_0:
	movl $820, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $821, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $822, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $823, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $824, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $825, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $826, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $827, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $828, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $829, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $830, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $831, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $832, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $833, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $834, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $835, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $836, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $837, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $838, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $839, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $5, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_42:
	addq $-8, %rsp
.initialize_program_42_0:
	movl $840, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $841, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $842, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $843, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $844, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $845, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $0, (%r8)
	movl $846, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $847, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $848, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $849, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $850, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $851, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $852, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $853, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $854, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $855, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $856, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $857, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $858, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $859, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $4, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_43:
	addq $-8, %rsp
.initialize_program_43_0:
	movl $860, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $861, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $862, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $863, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $4, (%r8)
	movl $864, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $865, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $866, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $867, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $868, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $869, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $870, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $871, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $872, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $5, (%r8)
	movl $873, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $874, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $6, (%r8)
	movl $875, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $876, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $2, (%r8)
	movl $877, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $1, (%r8)
	movl $878, %r8d
	imull $4, %r8d
	movslq %r8d, %rcx
	movq %rdi, %r8
	addq %rcx, %r8
	movl $3, (%r8)
	movl $879, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $1, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program_44:
	addq $-8, %rsp
.initialize_program_44_0:
	movl $880, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	movq %rdi, %r9
	addq %r8, %r9
	movl $6, (%r9)
	movl $0, %eax
	addq $8, %rsp
	ret
_c0_initialize_program:
	addq $-24, %rsp
	movq %rbx, 16(%rsp)
	movq %rdi, %r9
.initialize_program_0:
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_0
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_1
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_2
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_3
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_4
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_5
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_6
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_7
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_8
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_9
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_10
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_11
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_12
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_13
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_14
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_15
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_16
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_17
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_18
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_19
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_20
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_21
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_22
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_23
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_24
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_25
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_26
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_27
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_28
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_29
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_30
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_31
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_32
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_33
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_34
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_35
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_36
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_37
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_38
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_39
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_40
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_41
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_42
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_43
	movq %rbx, %r9
	movq %r9, %rdi
	movq %r9, %rbx
	callq _c0_initialize_program_44
	movq %rbx, %r9
	movl $881, %r8d
	imull $4, %r8d
	movslq %r8d, %r8
	addq %r8, %r9
	movl $7, (%r9)
	movl $0, %eax
	movq 16(%rsp), %rbx
	addq $24, %rsp
	ret
.ident	"15-411 L4 reference compiler"
